{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notebook_BOW_tf-idf.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"y_1I5MuFc4b9","colab_type":"code","colab":{}},"cell_type":"code","source":["#Importing required libraries\n","import re\n","import pandas as pd\n","import string\n","import os\n","from collections import defaultdict\n","import operator\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report\n","import collections\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pnUpjtGCyqZ1","colab_type":"code","colab":{}},"cell_type":"code","source":["#Loading the dataset\n","dataset = pd.read_csv('original-dataset.csv', skiprows=1, header=None)\n","print(dataset)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R8kp7oDT4DWG","colab_type":"code","colab":{}},"cell_type":"code","source":["#Converting dataset into a dictionary\n","mydict = dict(zip(dataset[0],dataset[1]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QbKKLLh14biD","colab_type":"code","colab":{}},"cell_type":"code","source":["#Printing the dictionary\n","print(mydict)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Fi3lWzTmSbjB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Analysing the most frequent and least frequent words\n","# Key:Value === Word:Count\n","frequency = defaultdict(int)\n","    \n","for key in mydict:\n","    dict = key.split(' ')\n","    dict = [item.lower() for item in dict]\n","    #write code here to remove stop words and punctuations or in a new code cell\n","    for f in dict:\n","        \n","        # Find all words which consist only of lowercase characters and are between length of 2-9.\n","        # We ignore all special characters such as !.$ and words containing numbers\n","        words = dict\n","        #print(words)\n","        for word in words:\n","            frequency[word] += 1\n","\n","sorted_words = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n","print(\"Top-10 most frequent words:\")\n","for word in sorted_words[:10]:\n","    print(word)\n","\n","print('----------------------------')\n","print(\"10 least frequent words:\")\n","for word in sorted_words[-10:-1]:\n","    print(word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WBnhxpnNfxsL","colab_type":"code","colab":{}},"cell_type":"code","source":["#Plotting Words Vs Frequency with words on the X-axis and frequency on the Y-axis\n","%matplotlib inline  \n","\n","fig = plt.figure()\n","fig.set_size_inches(20,10)\n","\n","plt.bar(range(len(sorted_words[:100])), [v for k, v in sorted_words[:100]] , align='center')\n","plt.xticks(range(len(sorted_words[:100])), [k for k, v in sorted_words[:100]])\n","locs, labels = plt.xticks()\n","plt.setp(labels, rotation=90)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zDBhOLKPRzNK","colab_type":"text"},"cell_type":"markdown","source":["**GENERATING** **THE** **BAG** **OF** **WORDS** **REPRESENTATION**"]},{"metadata":{"id":"gjLuUbGaIB_q","colab_type":"code","colab":{}},"cell_type":"code","source":["#Using CountVectorizer from ScikitLearn\n","#(line no, word id), frequency of the word in that line\n","vectorizer = CountVectorizer()\n","train_bow_set = vectorizer.fit_transform(dataset[0])\n","print(train_bow_set)\n","print( vectorizer.vocabulary_ )\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RD8Nvh1hs-k_","colab_type":"text"},"cell_type":"markdown","source":["**CONVERTING THE BAG OF WORDS TO TF_IDF(TERM FREQUENCY-INVERSE DOCUMENT FREQUENCY)**"]},{"metadata":{"id":"jQGGBSc7Ancm","colab_type":"code","colab":{}},"cell_type":"code","source":["#Using TfidfTransformer from ScikitLearn\n","tfidf_transformer = TfidfTransformer().fit(train_bow_set)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mfRp0sxeAsgP","colab_type":"code","colab":{}},"cell_type":"code","source":["print(tfidf_transformer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GDM3PtbnRDbK","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","messages_tfidf = tfidf_transformer.transform(train_bow_set)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eZdBQfVZRt6p","colab_type":"code","colab":{}},"cell_type":"code","source":["print (messages_tfidf.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYRx9VupuR5b","colab_type":"text"},"cell_type":"markdown","source":["**Predicting for a sample record**"]},{"metadata":{"id":"2gOb1QZ3BdFA","colab_type":"code","colab":{}},"cell_type":"code","source":["#test has the sample Problem_summary\n","test = 'There was a chargeoff reversal which generated an interest amount. There was also a payment on the same day which generated T'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z4EfMGW1BpYm","colab_type":"code","colab":{}},"cell_type":"code","source":["bow4 = vectorizer.transform([test])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlybcXakROy1","colab_type":"code","colab":{}},"cell_type":"code","source":["print(bow4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BjkOGl1LB_Ng","colab_type":"code","colab":{}},"cell_type":"code","source":["#Converting the Bog of words representation to TF_IDF\n","tfidf4 = tfidf_transformer.transform(bow4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CSEysCcWuprX","colab_type":"text"},"cell_type":"markdown","source":["**FITTING THE MULTINOMIAL NAIVE BAYES MODEL**"]},{"metadata":{"id":"VMdS2pZeCVvq","colab_type":"code","colab":{}},"cell_type":"code","source":["#using MultinomialNB from ScikitLearn\n","detect_model = MultinomialNB().fit(messages_tfidf,dataset[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9_DPnyy2CVsr","colab_type":"code","colab":{}},"cell_type":"code","source":["#Predicted Vs Expected output for he above sample record\n","print ('Predicted: ',detect_model.predict(tfidf4)[0] )\n","print ('Expected: ',dataset[1][0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KRJS-KP1vCVJ","colab_type":"text"},"cell_type":"markdown","source":["**PREDICTING FOR THE REMAINING SAMPLES**"]},{"metadata":{"id":"h5Zk9-7vC9NN","colab_type":"code","colab":{}},"cell_type":"code","source":["#all_predictions has the outputs predicted for each record\n","all_predictions = detect_model.predict(messages_tfidf)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-n-M8rl7SLZb","colab_type":"text"},"cell_type":"markdown","source":["**CLASSIFICATION REPORT**"]},{"metadata":{"id":"LAmZXzBwDE8X","colab_type":"code","colab":{}},"cell_type":"code","source":["print (classification_report(dataset[1], all_predictions))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CPxkYtefSRqq","colab_type":"text"},"cell_type":"markdown","source":["**ACCURACY SCORE**"]},{"metadata":{"id":"-fbhnLvpDMtp","colab_type":"code","colab":{}},"cell_type":"code","source":["accuracy_score(dataset[1],all_predictions)"],"execution_count":0,"outputs":[]}]}